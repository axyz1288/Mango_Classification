{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.EfficientNet import EfficientNet\n",
    "from model.Mango import Mango\n",
    "from model import Explainable\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "TRAIN_DIR = \"./data/C1-P1_Train/\"\n",
    "TRAIN_CSV = \"./data/train.csv\"\n",
    "DEV_DIR = \"./data/C1-P1_Dev/\"\n",
    "DEV_CSV = \"./data/dev.csv\"\n",
    "Mango_Class = {'A': 0, 'B': 1, 'C': 2}\n",
    "\n",
    "# hyper parameters\n",
    "DEPTH = 2\n",
    "WIDTH = 1.5\n",
    "RESOLUTION = 0.25\n",
    "BS_PER_GPU = 5\n",
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 3\n",
    "IMG_SIZE = int(224 * RESOLUTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomVerticalFlip(0.5),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomCrop(int(IMG_SIZE*2/3)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = Mango(TRAIN_CSV, TRAIN_DIR, Mango_Class, train_transform)\n",
    "testset = Mango(DEV_CSV, DEV_DIR, Mango_Class, test_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BS_PER_GPU, shuffle=False, num_workers=6)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BS_PER_GPU, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet(DEPTH, WIDTH, NUM_CHANNELS, IMG_SIZE, dropout=0.2, classes=NUM_CLASSES)\n",
    "model.load_state_dict(torch.load('./model/weights/Efficient_'+ str(DEPTH) + str(WIDTH) + '.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(testloader))\n",
    "imgs, labels = data['data'], data['label']\n",
    "saliencies = Explainable.get_saliency(imgs, labels, model)\n",
    "\n",
    "plt_num = 5\n",
    "fig, axes = plt.subplots(2, plt_num, figsize=(15, 8))\n",
    "for i in range(plt_num):\n",
    "    axes[0, i].set_title(labels[i])\n",
    "    axes[0, i].imshow(imgs[i].permute(1, 2, 0).detach().numpy())\n",
    "    axes[1, i].imshow(saliencies[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisher Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(testloader))\n",
    "imgs, labels = data['data'], data['label']\n",
    "fisher = Explainable.fisher_sensitivity(imgs, labels, model, 2, 0)\n",
    "\n",
    "plt_num = 5\n",
    "fig, axes = plt.subplots(2, plt_num, figsize=(15, 8))\n",
    "for i in range(plt_num):\n",
    "    axes[0, i].set_title(labels[i])\n",
    "    axes[0, i].imshow(imgs[i].permute(1, 2, 0).detach().numpy())\n",
    "    axes[1, i].imshow(fisher[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_num = 0\n",
    "plt_num = 5\n",
    "\n",
    "data = next(iter(testloader))\n",
    "imgs, labels = data['data'], data['label']\n",
    "filter_activations, filter_visualization = Explainable.filter_explaination(imgs, model, model.stage1)\n",
    "\n",
    "filter_num = round(filter_activations.shape[1] / plt_num) - 1 \n",
    "fig, axes = plt.subplots(filter_num + 2, plt_num, figsize=(15, 45))\n",
    "for i in range(plt_num):\n",
    "    axes[0, i].set_title(labels[i])\n",
    "    axes[0, i].imshow(imgs[i].permute(1, 2, 0))\n",
    "    axes[1, i].imshow(filter_visualization[i])\n",
    "for i in range(filter_num):\n",
    "    for j in range(plt_num):\n",
    "        axes[i+2, j].imshow(filter_activations[img_num][i * (plt_num) + j])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
